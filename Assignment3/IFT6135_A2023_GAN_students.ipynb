{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8y_h9goW_--j",
      "metadata": {
        "id": "8y_h9goW_--j"
      },
      "source": [
        "# IFT6135-A2023\n",
        "# Assignment 3: GAN Practical\n",
        "\n",
        "You must fill in your answers to various questions in this notebook, following which you must export this notebook to a Python file named `gan.py` and submit it on Gradescope.\n",
        "\n",
        "Only edit the functions specified in the PDF (and wherever marked â€“ `# WRITE CODE HERE`). Do not change definitions or edit the rest of the template, else the autograder will not work.\n",
        "\n",
        "**Make sure you request a GPU runtime!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AdbBo0_tQp8y",
      "metadata": {
        "id": "AdbBo0_tQp8y"
      },
      "source": [
        "## GAN Basics\n",
        "\n",
        "Generative Adversarial Autoencoders are generative models that are popularly used for unsupervised learning and are aimed at solving a two-player zero-sum game where a generator model is used to produce realistic samples which can fool a discriminator, which is tasked with distinguishing between real and fake samples.\n",
        "\n",
        "The formal objective for GANs can be seen as\n",
        "\n",
        "\\begin{align*}\n",
        "\\min_G \\max_D \\mathbb{E}_{x\\sim p_{data}} [\\log D(x)] + \\mathbb{E}_{z\\sim p_z} [\\log (1 - D(G(z))]\n",
        "\\end{align*}\n",
        "\n",
        "Where we can see that the job of the discriminator is to distinguish between data coming from the real distribution $x_{real} \\sim p_{data}$ and the data that is being generated by the generator $x_{fake} = G(z)$ where $z\\sim p_z$, where $p_z$ is just some prior distribution, often kept as $\\mathcal{N}(0, I)$. One can see the objective for $D(\\cdot)$ through the lens of classification, and in particular through the binary cross entropy loss.\n",
        "\n",
        "On the other hand, once the discriminator is trained to optimality, the job of the generator (the outer $\\min$) is to generate samples that fool the discriminator. In practice, instead of training the discriminator to optimality, we just alternate between training the discriminator for one step, and then the generator for one step, and we keep alternating. Further, the objective for the generator leads to poor gradient properties, and hence for training of the generator we aim to instead maximize\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}_{z\\sim p_z} [\\log D(G(z))]\n",
        "\\end{align*}\n",
        "\n",
        "Note that in both the equations, $G(z)$ is optimal only if it is able to fool the discriminator.\n",
        "\n",
        "For details about GANs, please refer to [Goodfellow's Paper](https://arxiv.org/abs/1406.2661)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f2d714",
      "metadata": {
        "id": "a1f2d714"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U datasets matplotlib tqdm\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torchvision.utils import make_grid, save_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision.transforms import Compose, ToTensor, Lambda, ToPILImage, CenterCrop, Resize\n",
        "from torchvision import transforms\n",
        "\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def fix_experiment_seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "fix_experiment_seed()\n",
        "\n",
        "results_folder = Path(\"./results_GAN\")\n",
        "results_folder.mkdir(exist_ok = True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bK_NDpHdO_fn",
      "metadata": {
        "id": "bK_NDpHdO_fn"
      },
      "source": [
        "## Set up the hyperparameters\n",
        "- Batch Size\n",
        "- Latent Dimensionality\n",
        "- Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5m7U3O5XC2i2",
      "metadata": {
        "id": "5m7U3O5XC2i2"
      },
      "outputs": [],
      "source": [
        "# Training Hyperparameters\n",
        "batch_size = 64   # Batch Size\n",
        "z_dim = 32        # Latent Dimensionality\n",
        "gen_lr = 1e-4     # Learning Rate for the Generator\n",
        "disc_lr = 1e-4    # Learning Rate for the Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lcwXsoUDEPwe",
      "metadata": {
        "id": "lcwXsoUDEPwe"
      },
      "outputs": [],
      "source": [
        "# Define Dataset Statistics\n",
        "image_size = 32\n",
        "input_channels = 1\n",
        "\n",
        "# Resize and Normalize the Data\n",
        "transform = Compose([\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
        "])\n",
        "\n",
        "# Helper Functions\n",
        "def show_image(image, nrow=8):\n",
        "  # Input: image\n",
        "  # Displays the image using matplotlib\n",
        "  grid_img = make_grid(image.detach().cpu(), nrow=nrow, padding=0)\n",
        "  plt.imshow(grid_img.permute(1, 2, 0))\n",
        "  plt.axis('off')\n",
        "\n",
        "def transforms_examples(examples):\n",
        "  # Helper function to perform transformations on the input images\n",
        "  if \"image\" in examples:\n",
        "     examples[\"pixel_values\"] = [transform(image) for image in examples[\"image\"]]\n",
        "     del examples[\"image\"]\n",
        "  else:\n",
        "     examples[\"pixel_values\"] = [transform(image) for image in examples[\"img\"]]\n",
        "     del examples[\"img\"]\n",
        "\n",
        "  return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6134d691",
      "metadata": {
        "id": "6134d691"
      },
      "outputs": [],
      "source": [
        "# Load dataset from the hub, normalize it and create the dataloader\n",
        "def get_dataloaders():\n",
        "  dataset = load_dataset(\"mnist\", cache_dir='./data')\n",
        "  transformed_dataset = dataset.with_transform(transforms_examples)\n",
        "  train_dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "  test_dataloader = DataLoader(transformed_dataset[\"test\"], batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "  return train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HfRQis_EP-yh",
      "metadata": {
        "id": "HfRQis_EP-yh"
      },
      "source": [
        "## Visualize the Data\n",
        "\n",
        "Let's visualize what our data actually looks like! We are using the [MNIST](https://huggingface.co/datasets/mnist). The MNIST dataset is a large collection of handwritten digits. It has a training set of 60,000 examples, and a test set of 10,000 examples. Please note that you don't need to download dataset yourself as the code we provided download the dataset for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e8273b",
      "metadata": {
        "id": "52e8273b"
      },
      "outputs": [],
      "source": [
        "# Visualize the Dataset\n",
        "def visualize():\n",
        "  train_dataloader, _ = get_dataloaders()\n",
        "  batch = next(iter(train_dataloader))\n",
        "  print(batch['pixel_values'].shape)\n",
        "\n",
        "  save_image((batch['pixel_values'] + 1.) * 0.5, './results_GAN/orig.png')\n",
        "  show_image((batch['pixel_values'] + 1.) * 0.5)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PSzDGCJvQPvm",
      "metadata": {
        "id": "PSzDGCJvQPvm"
      },
      "source": [
        "## Define the Model Architectures\n",
        "\n",
        "For a GAN model, we need two architectures, one for the Generator and the other for the discriminator. The generator a sample from $\\mathcal{N}(0, I)$ to the input space (which is the pixel space), while the discriminator maps a sample in the input space to a scalar, which determines (after a sigmoid) the probability of the input being from the real distribution.\n",
        "\n",
        "The architectures for both the generator and the discriminator networks have been provided to you for ease of experimentation. You are welcome to play with the architecture and change it for exploration purposes, but please stick to this architecture for the purpose of this homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812V5rIcHaaf",
      "metadata": {
        "id": "812V5rIcHaaf"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, channels, generator_features=32):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, generator_features * 4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(generator_features * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(generator_features * 4, generator_features * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(generator_features * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( generator_features * 2, generator_features * 1, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(generator_features * 1),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( generator_features * 1, channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.apply(weights_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels, discriminator_features=32):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(channels, discriminator_features, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(discriminator_features, discriminator_features * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(discriminator_features * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(discriminator_features * 2, discriminator_features * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(discriminator_features * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(discriminator_features * 4, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "\n",
        "        self.apply(weights_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2TprgdjZvoKm",
      "metadata": {
        "id": "2TprgdjZvoKm"
      },
      "source": [
        "Next, we define both the generator and the discriminator networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5126e21",
      "metadata": {
        "id": "a5126e21"
      },
      "outputs": [],
      "source": [
        "generator = Generator(z_dim, input_channels).to(device)\n",
        "discriminator = Discriminator(input_channels).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1Wmd1FIEFo9U",
      "metadata": {
        "id": "1Wmd1FIEFo9U"
      },
      "source": [
        "## Set the optimizers for each model\n",
        "\n",
        "Your task is to set each optimizer to be the Adam optimizer with the corresponding parameters, the learning rates kept as disc_lr and gen_lr respectively, and the betas hyperparameter set as (0.5, 0.999). You can use PyTorch's in-built Adam optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6T6vghqe-MFW",
      "metadata": {
        "id": "6T6vghqe-MFW"
      },
      "outputs": [],
      "source": [
        "from gan_solution import discriminator_optimizer, generator_optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2El5NXqZFs3I",
      "metadata": {
        "id": "2El5NXqZFs3I"
      },
      "source": [
        "## Define the criterion required for training.\n",
        "\n",
        "Your task is to identify the objective as a binary cross entropy objective and fill in the corresponding criterion. It should take as input un-normalized probabilities (without the sigmoid) and the true labels, and return the averaged loss. You can use one of PyTorch's in-built criterions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eDTpjMm-JSj",
      "metadata": {
        "id": "2eDTpjMm-JSj"
      },
      "outputs": [],
      "source": [
        "from gan_solution import criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XXqJc4_XGquo",
      "metadata": {
        "id": "XXqJc4_XGquo"
      },
      "source": [
        "## Define the Training functions for the discriminator and the generator\n",
        "\n",
        "Now, we need training scripts to run one step of discriminator training and one step of generator training respectively. In particular, the task is to fill the following functions:\n",
        "\n",
        "- discriminator_train: The function takes as input a set of real samples and a set of fake samples, and is supposed to return the average loss for training of the discriminator. To recap, the objective for the discriminator is $\\max_D \\sum\\limits_{i=1}^N \\log D(x_i) + \\sum\\limits_{i=1}^N \\log (1 - D(G(z_i))$, where minimization implies just taking negative of the objective. Here $x_i$ are the real samples while $z_i$ are noise samples used to generate fake samples.\n",
        "\n",
        "- generator_train: The function takes as input a set of fake samples and is supposed to return the average loss for training of the generator. To recap, the objective for the generator is $\\max_G \\sum\\limits_{i=1}^N \\log D(G(z_i))$, where minimization implies just taking negative of the objective. Here $z_i$ are noise samples used to generate fake samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fx3SbSTK-rPM",
      "metadata": {
        "id": "fx3SbSTK-rPM"
      },
      "outputs": [],
      "source": [
        "from gan_solution import discriminator_train, generator_train, sample"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7444b0b",
      "metadata": {
        "id": "f7444b0b"
      },
      "source": [
        "Finally, let's start training!\n",
        "Visualization of the samples generated, the original dataset and the reconstructions are saved locally in the notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92b12ed1",
      "metadata": {
        "id": "92b12ed1"
      },
      "outputs": [],
      "source": [
        "epochs = 25\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  train_dataloader, _ = get_dataloaders()\n",
        "  for epoch in range(epochs):\n",
        "    with tqdm(train_dataloader, unit=\"batch\", leave=False) as tepoch:\n",
        "      for batch in tepoch:\n",
        "        tepoch.set_description(f\"Epoch: {epoch}\")\n",
        "\n",
        "        noise = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
        "        fake = generator(noise)\n",
        "        real = batch['pixel_values'].to(device)\n",
        "\n",
        "        discriminator.zero_grad()\n",
        "        disc_loss = discriminator_train(discriminator, generator, real, fake.detach())\n",
        "        disc_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "\n",
        "        generator.zero_grad()\n",
        "        gen_loss = generator_train(discriminator, generator, fake)\n",
        "        gen_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "\n",
        "        tepoch.set_postfix(disc_loss=disc_loss.item(), gen_loss=gen_loss.item())\n",
        "\n",
        "    samples = sample(generator, 64)\n",
        "    save_image((real + 1.) * 0.5, './results_GAN/orig.png')\n",
        "    save_image((samples + 1.) * 0.5, f'./results_GAN/samples_{epoch}.png')\n",
        "\n",
        "  show_image((samples + 1.) * 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3PW1Xgz6-rbp",
      "metadata": {
        "id": "3PW1Xgz6-rbp"
      },
      "source": [
        "We can also visualize the interpolation between two points in the latent space: $z_1$ and $z_2$ by choosing points at equal intervals on the line from the two points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-b47g2Bj7IF-",
      "metadata": {
        "id": "-b47g2Bj7IF-"
      },
      "outputs": [],
      "source": [
        "from gan_solution import interpolate\n",
        "if __name__ == '__main__':\n",
        "  z_1 = torch.randn(1, z_dim, 1 ,1).to(device)\n",
        "  z_2 = torch.randn(1, z_dim, 1, 1).to(device)\n",
        "\n",
        "  interp = interpolate(generator, z_1, z_2, 10)\n",
        "  show_image((interp + 1.) * 0.5, nrow=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
